{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadind Bengaluru House Dataset :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area_type   availability                  location       size  \\\n",
       "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
       "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
       "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
       "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
       "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
       "\n",
       "   society total_sqft  bath  balcony   price  \n",
       "0  Coomee        1056   2.0      1.0   39.07  \n",
       "1  Theanmp       2600   5.0      3.0  120.00  \n",
       "2      NaN       1440   2.0      3.0   62.00  \n",
       "3  Soiewre       1521   3.0      1.0   95.00  \n",
       "4      NaN       1200   2.0      1.0   51.00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import io\n",
    "\n",
    "# Load the data\n",
    "Bengaluru_House_Data = pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
    "Bengaluru_House_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Dataset :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (Rows, Column) :- (13320, 9)\n",
      "\n",
      "Missing Values (Column wise) :-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "area_type          0\n",
       "availability       0\n",
       "location           1\n",
       "size              16\n",
       "society         5502\n",
       "total_sqft         0\n",
       "bath              73\n",
       "balcony          609\n",
       "price              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicates :- 529\n",
      "\n",
      "Summary :-\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13320 entries, 0 to 13319\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   area_type     13320 non-null  object \n",
      " 1   availability  13320 non-null  object \n",
      " 2   location      13319 non-null  object \n",
      " 3   size          13304 non-null  object \n",
      " 4   society       7818 non-null   object \n",
      " 5   total_sqft    13320 non-null  object \n",
      " 6   bath          13247 non-null  float64\n",
      " 7   balcony       12711 non-null  float64\n",
      " 8   price         13320 non-null  float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 936.7+ KB\n",
      "\n",
      "\n",
      "Descriptive Statistics:-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bath</th>\n",
       "      <td>13247.0</td>\n",
       "      <td>2.692610</td>\n",
       "      <td>1.341458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balcony</th>\n",
       "      <td>12711.0</td>\n",
       "      <td>1.584376</td>\n",
       "      <td>0.817263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>13320.0</td>\n",
       "      <td>112.565627</td>\n",
       "      <td>148.971674</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean         std  min   25%   50%    75%     max\n",
       "bath     13247.0    2.692610    1.341458  1.0   2.0   2.0    3.0    40.0\n",
       "balcony  12711.0    1.584376    0.817263  0.0   1.0   2.0    2.0     3.0\n",
       "price    13320.0  112.565627  148.971674  8.0  50.0  72.0  120.0  3600.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No mis-spaced column names found.\n",
      "\n",
      "Total No. of Unique Value for each Columns :-\n",
      "area_type = 4\n",
      "availability = 81\n",
      "location = 1306\n",
      "size = 32\n",
      "society = 2689\n",
      "total_sqft = 2117\n",
      "bath = 20\n",
      "balcony = 5\n",
      "price = 1994\n"
     ]
    }
   ],
   "source": [
    "## Check Shape\n",
    "Bengaluru_House_Data_shape = Bengaluru_House_Data.shape\n",
    "print(f\"Shape (Rows, Column) :- {Bengaluru_House_Data_shape}\")\n",
    "\n",
    "\n",
    "## Check Missing Value\n",
    "# Columns which has null values\n",
    "Bengaluru_House_Data_missing_value = Bengaluru_House_Data.isnull().sum()\n",
    "print(\"\\nMissing Values (Column wise) :-\")\n",
    "display(Bengaluru_House_Data_missing_value)\n",
    "\n",
    "\n",
    "## Check Duplicates\n",
    "Bengaluru_House_Data_duplicates = Bengaluru_House_Data.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates :- {Bengaluru_House_Data_duplicates}\")\n",
    "\n",
    "\n",
    "## Check Summary\n",
    "# Capture the output of df.info() as a string\n",
    "Bengaluru_House_Data_summary_buffer = io.StringIO()\n",
    "Bengaluru_House_Data.info(buf=Bengaluru_House_Data_summary_buffer)\n",
    "Bengaluru_House_Data_summary_str = Bengaluru_House_Data_summary_buffer.getvalue()\n",
    "# Close the buffer\n",
    "Bengaluru_House_Data_summary_buffer.close()\n",
    "# Now, output_str contains the info() output as a string\n",
    "print(\"\\nSummary :-\")\n",
    "print(Bengaluru_House_Data_summary_str)\n",
    "\n",
    "\n",
    "## Check Descriptive Summary\n",
    "Bengaluru_House_Data_descriptive_summary =Bengaluru_House_Data.describe().T\n",
    "print(\"\\nDescriptive Statistics:-\")\n",
    "display(Bengaluru_House_Data_descriptive_summary)\n",
    "\n",
    "\n",
    "## Check Mis-Spaced\n",
    "Bengaluru_House_Data_mis_spaced_columns = [col for col in Bengaluru_House_Data.columns if ' ' in col]\n",
    "\n",
    "if Bengaluru_House_Data_mis_spaced_columns:\n",
    "    print(\"\\nMis-spaced column names :-\")\n",
    "    for col in Bengaluru_House_Data_mis_spaced_columns:\n",
    "        print(f\"'{col}'\")\n",
    "else:\n",
    "    print(\"\\nNo mis-spaced column names found.\")\n",
    "\n",
    "\n",
    "## Check No. of Unique Value\n",
    "print(\"\\nTotal No. of Unique Value for each Columns :-\")\n",
    "for col_name in Bengaluru_House_Data.columns:\n",
    "    Bengaluru_House_Data_No_unique_value = len(Bengaluru_House_Data[col_name].unique())\n",
    "    print(F\"{col_name} = {Bengaluru_House_Data_No_unique_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Miassing Values, Label Encoding, Feature Engineering and Modify Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **`Handling Duplicates`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bengaluru_House_Data.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  `Area Type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label encoding mapping\n",
    "area_type_mapping = {'Super built-up  Area': 3,\n",
    "                     'Plot  Area': 2,\n",
    "                     'Built-up  Area': 1,\n",
    "                     'Carpet  Area': 0}\n",
    "\n",
    "# Perform label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "Bengaluru_House_Data['area_type_encoded'] = Bengaluru_House_Data['area_type'].map(area_type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  `Availability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_availability(avail):\n",
    "    if avail == 'Ready To Move' or avail == 'Immediate Possession':\n",
    "        return avail\n",
    "    else:\n",
    "        return 'Date-Based'\n",
    "\n",
    "# Apply the categorize_availability function to create a new column\n",
    "Bengaluru_House_Data['availability'] = Bengaluru_House_Data['availability'].apply(categorize_availability)\n",
    "\n",
    "# Define the label encoding mapping\n",
    "availability_mapping = {'Ready To Move': 1,\n",
    "                        'Immediate Possession': 1,  # Add this line\n",
    "                        'Date-Based': 0\n",
    "                        }\n",
    "\n",
    "# Perform label encoding\n",
    "Bengaluru_House_Data['availability_category'] = Bengaluru_House_Data['availability'].map(availability_mapping).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  `Location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode(df, target, categorical):\n",
    "    target_encoded = {}\n",
    "    global_mean = df[target].mean()\n",
    "    for category in categorical:\n",
    "        category_mean = df.groupby(category)[target].mean()\n",
    "        category_count = df.groupby(category)[target].count()\n",
    "        category_encoded = (category_mean * category_count + global_mean) / (category_count + 1)\n",
    "        target_encoded[category] = category_encoded\n",
    "    return target_encoded\n",
    "\n",
    "target_encoded_location = target_encode(Bengaluru_House_Data, 'price', ['location'])\n",
    "Bengaluru_House_Data['location_encoded'] = Bengaluru_House_Data['location'].map(target_encoded_location['location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  `Size Or No. fo Bedroom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No of Bedrrom of the Bengaluru House \n",
    "Bengaluru_House_Data['size'] = Bengaluru_House_Data['size'].str.replace('BHK', '').str.replace('Bedroom', '').str.replace('RK','')\n",
    "Bengaluru_House_Data.dropna(subset=['size'], inplace=True)\n",
    "Bengaluru_House_Data['size'] = Bengaluru_House_Data['size'].astype(int)\n",
    "Bengaluru_House_Data.rename(columns={'size': 'No. of Bedroom'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  `society`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bengaluru_House_Data = Bengaluru_House_Data.drop(columns=['society'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  `total_sqft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bengaluru_House_Data['total_sqft'] = Bengaluru_House_Data['total_sqft'].str.replace('Sq. Meter', '')\n",
    "\n",
    "def parse_total_sqft(total_sqft):\n",
    "    try:\n",
    "        parts = total_sqft.split(\" -\")\n",
    "        if len(parts) == 1:\n",
    "            return float(parts[0])\n",
    "        else:\n",
    "            return (float(parts[0]) + float(parts[1])) / 2\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the parsing function to the 'total_sqft' column\n",
    "Bengaluru_House_Data['total_sqft'] = Bengaluru_House_Data['total_sqft'].apply(parse_total_sqft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  `bath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No of Bathroom of the Bengaluru House \n",
    "Bengaluru_House_Data['bath'] = Bengaluru_House_Data['bath'].fillna(0)\n",
    "Bengaluru_House_Data['bath'] = Bengaluru_House_Data['bath'].astype(int)\n",
    "Bengaluru_House_Data.rename(columns={'bath': 'No. of Bathroom'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  `balcony`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No of Bathroom of the Bengaluru House \n",
    "Bengaluru_House_Data['balcony'] = Bengaluru_House_Data['balcony'].fillna(0)\n",
    "Bengaluru_House_Data['balcony'] = Bengaluru_House_Data['balcony'].astype(int)\n",
    "Bengaluru_House_Data.rename(columns={'balcony': 'No. of Balcony'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Again Before going for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicates :- 129\n",
      "\n",
      "Missing Values (Column wise) :-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "area_type                 0\n",
       "availability              0\n",
       "location                  1\n",
       "No. of Bedroom            0\n",
       "total_sqft               29\n",
       "No. of Bathroom           0\n",
       "No. of Balcony            0\n",
       "price                     0\n",
       "area_type_encoded         0\n",
       "availability_category     0\n",
       "location_encoded          1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Bengaluru_House_Data_duplicates = Bengaluru_House_Data.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates :- {Bengaluru_House_Data_duplicates}\")\n",
    "\n",
    "Bengaluru_House_Data_missing_value = Bengaluru_House_Data.isnull().sum()\n",
    "print(\"\\nMissing Values (Column wise) :-\")\n",
    "display(Bengaluru_House_Data_missing_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing these basic Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bengaluru_House_Data.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bengaluru_House_Data['location'].fillna(Bengaluru_House_Data['location'].mode()[0], inplace=True)\n",
    "Bengaluru_House_Data['total_sqft'].fillna(Bengaluru_House_Data['total_sqft'].mean(), inplace=True)\n",
    "Bengaluru_House_Data['location_encoded'].fillna(Bengaluru_House_Data['location_encoded'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know we are good to go for further Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X contains the features and y contains the target variable (price)\n",
    "X = Bengaluru_House_Data[['area_type_encoded','availability_category','location_encoded','No. of Bedroom','total_sqft','No. of Bathroom','No. of Balcony']]\n",
    "y = Bengaluru_House_Data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12646, 7), (12646,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Training\n",
    "svm_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Evaluation\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.No-01    In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the context of predicting house prices using an SVM regression model, several regression metrics are commonly used to evaluate the model's performance.**\n",
    "\n",
    "**`Let's Calculate the metrics` :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 20646.778013454208\n",
      "Root Mean Squared Error (RMSE): 143.68986746968002\n",
      "Mean Absolute Error (MAE): 44.60814817174127\n",
      "R-squared (R2): 0.2735174484813252\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate R-squared (R2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 30.553202201231084\n",
      "Coefficient of Determination (CD): 0.2735174484813252\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def coefficient_of_determination(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "\n",
    "# Calculate Coefficient of Determination (CD)\n",
    "cd = coefficient_of_determination(y_test, y_pred)\n",
    "print(\"Coefficient of Determination (CD):\", cd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**According to these metrics, the choice of the best regression metric depends on the specific requirements and preferences of the analysis.**\n",
    "\n",
    "**`However`, considering common practices and the characteristics of the calculated metrics, `here's some insight` :**\n",
    "\n",
    "1. **Mean Squared Error (MSE)** and **Root Mean Squared Error (RMSE)**: These metrics penalize larger errors more heavily than smaller errors, making them sensitive to outliers. While they provide a measure of the average squared deviation of predictions from the actual values, they might not be very intuitive for interpretation in terms of house prices. However, they are commonly used for assessing model accuracy.\n",
    "\n",
    "2. **Mean Absolute Error (MAE)**: MAE represents the average absolute difference between predicted and actual values. It is more robust to outliers compared to MSE and RMSE because it doesn't square the errors. MAE provides a straightforward interpretation in the same units as the target variable (e.g., dollars for house prices).\n",
    "\n",
    "3. **R-squared (R2)** and **Coefficient of Determination (CD)**: R-squared represents the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where a higher value indicates a better fit. However, it doesn't directly provide insight into the magnitude of prediction errors.\n",
    "\n",
    "4. **Mean Absolute Percentage Error (MAPE)**: MAPE measures the percentage difference between predicted and actual values. It's useful for understanding the average percentage error relative to the actual values, making it interpretable, especially for stakeholders who may want to understand prediction accuracy in percentage terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Considering these insights and Calculated metrics`**, **Mean Absolute Error (MAE) may be the most suitable regression metric in this situation**. It provides a clear interpretation of the average absolute difference between predicted and actual house prices, making it easier to understand and communicate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.No-02    You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the goal is to predict the actual price of a house as accurately as possible, it's essential to choose an evaluation metric that directly reflects the accuracy of the predictions.**\n",
    "\n",
    "**`In this scenario, considering insights and the calculated metrics value` :**\n",
    "\n",
    "1. **Mean Squared Error (MSE)** measures the average squared difference between predicted and actual values. It provides a measure of the average magnitude of errors. However, it doesn't directly translate to the accuracy in terms of actual house prices.\n",
    "\n",
    "2. **R-squared (R2)** represents the proportion of the variance in the dependent variable (house prices) that is predictable from the independent variables. A higher R-squared indicates that a larger proportion of the variability in house prices is explained by the model. However, R-squared does not provide information about the magnitude of prediction errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Given that the goal is to predict house prices as accurately as possible,` **Then Mean Squared Error (MSE) would be more appropriate as an evaluation metric. This is because MSE directly quantifies the average squared difference between predicted and actual house prices, providing a clear indication of the model's predictive accuracy in terms of minimizing prediction errors. By minimizing MSE, the model aims to make predictions that are as close as possible to the actual house prices, which aligns with the goal of accurately predicting house prices.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.No-03    You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`When dealing with a dataset that contains a significant number of outliers`, **it's important to choose a regression metric that is robust to outliers. One of the regression metric is the Mean Absolute Error (MAE).**\n",
    "\n",
    "**Mean Absolute Error (MAE)** is calculated by taking the average of the absolute differences between the predicted and actual values. It is less sensitive to outliers compared to other metrics like Mean Squared Error (MSE) or Root Mean Squared Error (RMSE) because it does not square the errors.\n",
    "\n",
    "Using MAE as the regression metric for your Support Vector Machine (SVM) model would be appropriate in this scenario because it provides a more balanced evaluation of the model's performance, even when dealing with outliers. By using MAE, the model's performance won't be heavily influenced by extreme values in the dataset, allowing for a more reliable assessment of its predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.No-04    You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are very close, it indicates that the scale of the errors is consistent across the dataset. `In such cases, RMSE might be preferred over MSE`.**\n",
    "\n",
    "`The reason` is that RMSE is in the same unit as the target variable, making it more interpretable compared to MSE, which is in squared units. This can be advantageous for communication purposes, especially if stakeholders are more familiar with the original scale of the target variable.\n",
    "\n",
    "`Therefore`, in this case where MSE and RMSE are very close, it would be reasonable to choose RMSE as the metric to evaluate the performance of SVM regression model with a polynomial kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.No.05    You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When the goal is to measure how well a regression model explains the variance in the target variable, `the most appropriate evaluation metric is the coefficient of determination`, commonly known as** $ R^2 $ **(R-squared).**\n",
    "\n",
    "The $ R^2 $ score quantifies the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where 1 indicates perfect prediction and 0 indicates that the model does not explain any of the variability in the target variable.\n",
    "\n",
    "`For comparing different SVM regression models with different kernels (linear, polynomial, and RBF)`, **using** $ R^2 $ **as the evaluation metric would be suitable**. This metric provides insight into how well each model captures the variance in the target variable, allowing for an informed comparison of their performance in terms of explaining the data variability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
